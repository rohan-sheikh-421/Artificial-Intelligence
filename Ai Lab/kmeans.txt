kmeans

import numpy as np
import pandas as pd
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Sample data
data = {
    'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'y': [1, 2, 1, 2, 3, 4, 5, 6, 5, 6]
}
df = pd.DataFrame(data)

# Extracting the values as a numpy array
X = df.values

# Define the number of clusters
k = 3

# Create and fit the model
kmeans = KMeans(n_clusters=k, random_state=0)
kmeans.fit(X)

# Getting the cluster centroids
centroids = kmeans.cluster_centers_

# Getting the labels
labels = kmeans.labels_

# Add the cluster labels to the dataframe
df['Cluster'] = labels

# Plotting the results
plt.scatter(df['x'], df['y'], c=df['Cluster'], cmap='viridis', marker='o')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x')
plt.xlabel('x')
plt.ylabel('y')
plt.title('KMeans Clustering')
plt.show()

print("Cluster centroids:\n", centroids)
print("Data with cluster labels:\n", df)

------------------------------------------------------------------------------

K mediod

import numpy as np
import pandas as pd
from sklearn_extra.cluster import KMedoids
import matplotlib.pyplot as plt

# Sample data
data = {
    'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],
    'y': [1, 2, 1, 2, 3, 4, 5, 6, 5, 6]
}
df = pd.DataFrame(data)

# Extracting the values as a numpy array
X = df.values

# Define the number of clusters
k = 3

# Create and fit the model
kmedoids = KMedoids(n_clusters=k, random_state=0)
kmedoids.fit(X)

# Getting the cluster medoids
medoids = kmedoids.cluster_centers_

# Getting the labels
labels = kmedoids.labels_

# Add the cluster labels to the dataframe
df['Cluster'] = labels

# Plotting the results
plt.scatter(df['x'], df['y'], c=df['Cluster'], cmap='viridis', marker='o')
plt.scatter(medoids[:, 0], medoids[:, 1], c='red', marker='x')
plt.xlabel('x')
plt.ylabel('y')
plt.title('KMedoids Clustering')
plt.show()

print("Cluster medoids:\n", medoids)
print("Data with cluster labels:\n", df)

-----------------------------------------------------------------------------

Astar

import heapq

class Node:
    def __init__(self, position, parent=None):
        self.position = position
        self.parent = parent
        self.g = 0  # Cost from start to node
        self.h = 0  # Heuristic cost estimate to goal
        self.f = 0  # Total cost (f = g + h)
    
    def __eq__(self, other):
        return self.position == other.position
    
    def __lt__(self, other):
        return self.f < other.f

def heuristic(a, b):
    # Manhattan distance
    return abs(a[0] - b[0]) + abs(a[1] - b[1])

def a_star(grid, start, end):
    open_list = []
    closed_list = set()
    
    start_node = Node(start)
    end_node = Node(end)
    
    heapq.heappush(open_list, start_node)
    
    while open_list:
        current_node = heapq.heappop(open_list)
        closed_list.add(current_node.position)
        
        if current_node == end_node:
            path = []
            while current_node:
                path.append(current_node.position)
                current_node = current_node.parent
            return path[::-1]
        
        (x, y) = current_node.position
        neighbors = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]
        
        for next_position in neighbors:
            (nx, ny) = next_position
            if 0 <= nx < len(grid) and 0 <= ny < len(grid[0]) and grid[nx][ny] == 0:
                neighbor_node = Node(next_position, current_node)
                if neighbor_node.position in closed_list:
                    continue
                neighbor_node.g = current_node.g + 1
                neighbor_node.h = heuristic(neighbor_node.position, end_node.position)
                neighbor_node.f = neighbor_node.g + neighbor_node.h
                
                if any(open_node for open_node in open_list if neighbor_node == open_node and neighbor_node.g > open_node.g):
                    continue
                
                heapq.heappush(open_list, neighbor_node)
    
    return None  # No path found

# Example grid (0 = walkable, 1 = obstacle)
grid = [
    [0, 1, 0, 0, 0, 0],
    [0, 1, 0, 1, 1, 0],
    [0, 0, 0, 0, 1, 0],
    [0, 1, 1, 0, 1, 0],
    [0, 0, 0, 0, 0, 0]
]

start = (0, 0)
end = (4, 5)
path = a_star(grid, start, end)

if path:
    print("Path found:", path)
else:
    print("No path found.")

----------------------------------------------
import heapq

class Node:
    def __init__(self, position, parent=None):
        self.position = position
        self.parent = parent
        self.g = 0  # Cost from start to node
        self.h = 0  # Heuristic cost estimate to goal
        self.f = 0  # Total cost (f = g + h)
    
    def __eq__(self, other):
        return self.position == other.position
    
    def __lt__(self, other):
        return self.f < other.f

def heuristic(a, b):
    # Manhattan distance as heuristic
    return abs(a[0] - b[0]) + abs(a[1] - b[1])

def a_star(grid, start, end):
    open_list = []
    closed_list = set()
    
    start_node = Node(start)
    end_node = Node(end)
    
    heapq.heappush(open_list, start_node)
    
    while open_list:
        current_node = heapq.heappop(open_list)
        closed_list.add(current_node.position)
        
        if current_node == end_node:
            path = []
            while current_node:
                path.append(current_node.position)
                current_node = current_node.parent
            return path[::-1]
        
        (x, y) = current_node.position
        neighbors = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]
        
        for next_position in neighbors:
            (nx, ny) = next_position
            if 0 <= nx < len(grid) and 0 <= ny < len(grid[0]) and grid[nx][ny] == 0:
                neighbor_node = Node(next_position, current_node)
                if neighbor_node.position in closed_list:
                    continue
                neighbor_node.g = current_node.g + 1
                neighbor_node.h = heuristic(neighbor_node.position, end_node.position)
                neighbor_node.f = neighbor_node.g + neighbor_node.h
                
                if any(open_node for open_node in open_list if neighbor_node == open_node and neighbor_node.g > open_node.g):
                    continue
                
                heapq.heappush(open_list, neighbor_node)
    
    return None  # No path found

# Example grid (0 = walkable, 1 = obstacle)
grid = [
    [0, 1, 0, 0, 0, 0],
    [0, 1, 0, 1, 1, 0],
    [0, 0, 0, 0, 1, 0],
    [0, 1, 1, 0, 1, 0],
    [0, 0, 0, 0, 0, 0]
]

start = (0, 0)
end = (4, 5)
path = a_star(grid, start, end)

if path:
    print("Path found:", path)
else:
    print("No path found.")

--------------------------------------------------------

bfs

from collections import deque

def bfs(grid, start, end):
    # Directions for moving in the grid (up, down, left, right)
    directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]
    
    # Queue for BFS and a set to track visited nodes
    queue = deque([start])
    visited = set()
    visited.add(start)
    
    # Dictionary to track the path
    parent = {start: None}
    
    while queue:
        current = queue.popleft()
        
        # If we reached the end, reconstruct the path
        if current == end:
            path = []
            while current:
                path.append(current)
                current = parent[current]
            return path[::-1]
        
        # Explore neighbors
        for direction in directions:
            neighbor = (current[0] + direction[0], current[1] + direction[1])
            if 0 <= neighbor[0] < len(grid) and 0 <= neighbor[1] < len(grid[0]):
                if grid[neighbor[0]][neighbor[1]] == 0 and neighbor not in visited:
                    queue.append(neighbor)
                    visited.add(neighbor)
                    parent[neighbor] = current
    
    return None  # No path found

# Example grid (0 = walkable, 1 = obstacle)
grid = [
    [0, 1, 0, 0, 0, 0],
    [0, 1, 0, 1, 1, 0],
    [0, 0, 0, 0, 1, 0],
    [0, 1, 1, 0, 1, 0],
    [0, 0, 0, 0, 0, 0]
]

start = (0, 0)
end = (4, 5)
path = bfs(grid, start, end)

if path:
    print("Path found:", path)
else:
    print("No path found.")

-------------------------------------------------------------------------------------

dfs

def dfs(grid, start, end):
    # Stack for DFS and a set to track visited nodes
    stack = [start]
    visited = set()
    visited.add(start)
    
    # Dictionary to track the path
    parent = {start: None}
    
    while stack:
        current = stack.pop()
        
        # If we reached the end, reconstruct the path
        if current == end:
            path = []
            while current:
                path.append(current)
                current = parent[current]
            return path[::-1]
        
        # Directions for moving in the grid (up, down, left, right)
        directions = [(-1, 0), (1, 0), (0, -1), (0, 1)]
        
        # Explore neighbors
        for direction in directions:
            neighbor = (current[0] + direction[0], current[1] + direction[1])
            if 0 <= neighbor[0] < len(grid) and 0 <= neighbor[1] < len(grid[0]):
                if grid[neighbor[0]][neighbor[1]] == 0 and neighbor not in visited:
                    stack.append(neighbor)
                    visited.add(neighbor)
                    parent[neighbor] = current
    
    return None  # No path found

# Example grid (0 = walkable, 1 = obstacle)
grid = [
    [0, 1, 0, 0, 0, 0],
    [0, 1, 0, 1, 1, 0],
    [0, 0, 0, 0, 1, 0],
    [0, 1, 1, 0, 1, 0],
    [0, 0, 0, 0, 0, 0]
]

start = (0, 0)
end = (4, 5)
path = dfs(grid, start, end)

if path:
    print("Path found:", path)
else:
    print("No path found.")


------------------------------------------------------------------

genetic algorithm

import random

# Genetic Algorithm parameters
POPULATION_SIZE = 100
GENES = 8  # Length of binary chromosome
GENERATIONS = 1000
MUTATION_RATE = 0.01

# Fitness function: f(x) = x^2, where x is a binary string interpreted as an integer
def fitness(individual):
    x = int("".join(map(str, individual)), 2)
    return x * x

# Create initial population
def create_population():
    return [[random.randint(0, 1) for _ in range(GENES)] for _ in range(POPULATION_SIZE)]

# Tournament selection
def select(population):
    tournament_size = 3
    selected = random.sample(population, tournament_size)
    selected = sorted(selected, key=lambda ind: fitness(ind), reverse=True)
    return selected[0]

# Single-point crossover
def crossover(parent1, parent2):
    point = random.randint(1, GENES - 1)
    child1 = parent1[:point] + parent2[point:]
    child2 = parent2[:point] + parent1[point:]
    return child1, child2

# Mutation
def mutate(individual):
    for i in range(GENES):
        if random.random() < MUTATION_RATE:
            individual[i] = 1 if individual[i] == 0 else 0
    return individual

# Main Genetic Algorithm
def genetic_algorithm():
    population = create_population()

    for generation in range(GENERATIONS):
        new_population = []
        
        for _ in range(POPULATION_SIZE // 2):
            parent1 = select(population)
            parent2 = select(population)
            child1, child2 = crossover(parent1, parent2)
            new_population.extend([mutate(child1), mutate(child2)])
        
        population = new_population
        
        # Optional: Track and print the best individual in each generation
        best_individual = max(population, key=lambda ind: fitness(ind))
        best_fitness = fitness(best_individual)
        print(f"Generation {generation + 1}: Best Fitness = {best_fitness}, Best Individual = {best_individual}")

    # Final best solution
    best_individual = max(population, key=lambda ind: fitness(ind))
    best_fitness = fitness(best_individual)
    print(f"Final Solution: Best Fitness = {best_fitness}, Best Individual = {best_individual}")

genetic_algorithm()


------------------------------------------------------------------------------------------------------

evaluation metrics 

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def evaluate_model(y_true, y_pred):
    """
    Evaluate the performance of a classification model.
    
    Parameters:
    - y_true: list or numpy array of true labels
    - y_pred: list or numpy array of predicted labels
    
    Returns:
    - A dictionary with accuracy, precision, recall, and F1 score.
    """
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')
    
    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1
    }

# Example usage
if __name__ == "__main__":
    # Example true and predicted labels
    y_true = [0, 1, 1, 0, 1, 0, 1, 1, 0, 0]
    y_pred = [0, 1, 0, 0, 1, 0, 1, 0, 0, 1]
    
    results = evaluate_model(y_true, y_pred)
    
    print(f"Accuracy: {results['accuracy']}")
    print(f"Precision: {results['precision']}")
    print(f"Recall: {results['recall']}")
    print(f"F1 Score: {results['f1_score']}")

------------------------------------------------------------------------------------

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report
from sklearn.preprocessing import label_binarize

def plot_confusion_matrix(y_true, y_pred, labels):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title('Confusion Matrix')
    plt.show()

def plot_roc_curve(y_true, y_prob, n_classes):
    if n_classes == 2:
        fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])
        roc_auc = roc_auc_score(y_true, y_prob[:, 1])
        plt.figure()
        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic (ROC) Curve')
        plt.legend(loc="lower right")
        plt.show()
    else:
        # Binarize the output
        y_true = label_binarize(y_true, classes=[i for i in range(n_classes)])
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        for i in range(n_classes):
            fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_prob[:, i])
            roc_auc[i] = roc_auc_score(y_true[:, i], y_prob[:, i])
        plt.figure()
        for i in range(n_classes):
            plt.plot(fpr[i], tpr[i], lw=2, label='ROC curve of class {0} (area = {1:0.2f})'
                                                 ''.format(i, roc_auc[i]))
        plt.plot([0, 1], [0, 1], 'k--', lw=2)
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic (ROC) Curve')
        plt.legend(loc="lower right")
        plt.show()

def evaluate_model(y_true, y_pred, y_prob, labels):
    print("Classification Report:\n")
    print(classification_report(y_true, y_pred, target_names=labels))
    
    plot_confusion_matrix(y_true, y_pred, labels)
    
    n_classes = len(labels)
    plot_roc_curve(y_true, y_prob, n_classes)

# Example usage
if __name__ == "__main__":
    # Example true and predicted labels and predicted probabilities
    y_true = np.array([0, 1, 2, 2, 0, 1, 0, 0, 1, 2])
    y_pred = np.array([0, 1, 0, 2, 0, 1, 0, 0, 1, 1])
    y_prob = np.array([[0.9, 0.05, 0.05],
                       [0.1, 0.8, 0.1],
                       [0.4, 0.4, 0.2],
                       [0.1, 0.2, 0.7],
                       [0.8, 0.1, 0.1],
                       [0.2, 0.7, 0.1],
                       [0.9, 0.05, 0.05],
                       [0.85, 0.1, 0.05],
                       [0.2, 0.7, 0.1],
                       [0.1, 0.6, 0.3]])
    labels = ['Class 0', 'Class 1', 'Class 2']
    
    evaluate_model(y_true, y_pred, y_prob, labels)

